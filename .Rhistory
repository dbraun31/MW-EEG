facet_grid(subject~PC) +
theme_bw() +
theme(strip.background = element_rect(fill=NA))
d %>%
gather(PC, loading, PC1:PC3) %>%
inner_join(eigen_df) %>%
head()
ggplot(aes(label=item, size = abs(loading), color = loading)) +
geom_text_wordcloud(area_corr = TRUE) +
scale_size_area(aes(max_size = eigens*60)) +
scale_color_gradientn(colors = rev(brewer_pal(type='div')(9))) +
facet_grid(subject~PC) +
theme_bw() +
theme(strip.background = element_rect(fill=NA))
d %>%
gather(PC, loading, PC1:PC3) %>%
inner_join(eigen_df) %>%
ggplot(aes(label=item, size = abs(loading), color = loading)) +
geom_text_wordcloud(area_corr = TRUE) +
scale_size_area(aes(max_size = eigens*60)) +
scale_color_gradientn(colors = rev(brewer_pal(type='div')(9))) +
facet_grid(subject~PC) +
theme_bw() +
theme(strip.background = element_rect(fill=NA))
d %>%
gather(PC, loading, PC1:PC3) %>%
inner_join(eigen_df) %>%
ggplot(aes(label=item, size = abs(loading), color = loading)) +
geom_text_wordcloud(area_corr = TRUE) +
scale_size_area(aes(max_size = eigens*600)) +
scale_color_gradientn(colors = rev(brewer_pal(type='div')(9))) +
facet_grid(subject~PC) +
theme_bw() +
theme(strip.background = element_rect(fill=NA))
d %>%
gather(PC, loading, PC1:PC3) %>%
inner_join(eigen_df) %>%
ggplot(aes(label=item, size = abs(loading), color = loading)) +
geom_text_wordcloud(area_corr = TRUE) +
scale_size_area(max_size = eigens*600) +
scale_color_gradientn(colors = rev(brewer_pal(type='div')(9))) +
facet_grid(subject~PC) +
theme_bw() +
theme(strip.background = element_rect(fill=NA))
d %>%
gather(PC, loading, PC1:PC3) %>%
inner_join(eigen_df) %>%
ggplot(aes(label=item, size = abs(loading), color = loading)) +
geom_text_wordcloud(area_corr = TRUE) +
scale_size_area(max_size = 30) +
scale_color_gradientn(colors = rev(brewer_pal(type='div')(9))) +
facet_grid(subject~PC) +
theme_bw() +
theme(strip.background = element_rect(fill=NA))
content <- TRUE
if (content) {
items <- c('att', 'past', 'fut', 'self', 'ppl', 'arou', 'aff', 'image', 'ling')
} else {
items <- c('eng', 'mvmt', 'delib')
}
# Keep only subjects with 50 observations
subject_mask <- d %>%
group_by(subject) %>%
summarize(count = n()) %>%
filter(count >= 50) %>%
pull(subject)
d <- d[d$subject %in% subject_mask, ]
# Drop low confidence (< 75) responses
d <- d[d$conf > 75, c('subject', items)]
rm(list=ls())
library(tidyverse)
library(ggraph)
source('scripts/helpers/normalize.r')
#source('scripts/helpers/plot_rotation.r')
d <- read.csv('data/behavioral_data/MW_EEG_behavioral.csv')
# Content or movement items
content <- TRUE
if (content) {
items <- c('att', 'past', 'fut', 'self', 'ppl', 'arou', 'aff', 'image', 'ling')
} else {
items <- c('eng', 'mvmt', 'delib')
}
# Keep only subjects with 50 observations
subject_mask <- d %>%
group_by(subject) %>%
summarize(count = n()) %>%
filter(count >= 50) %>%
pull(subject)
d <- d[d$subject %in% subject_mask, ]
# Drop low confidence (< 75) responses
d <- d[d$conf > 75, c('subject', items)]
# Normalize
d <- normalize_subject_item(d)
# Run PCAs
subject_pcas <- list()
for (subject in d$subject) {
pca_data <- d[d$subject==subject, colnames(d) != 'subject']
subject_pcas[['rotations']][[paste0('subject', subject)]] <- prcomp(pca_data)$rotation[,1:3]
subject_pcas[['eigens']][[paste0('subject', subject)]] <- eigen(cov(pca_data))$values
}
# Compute distance and cluster
distance_matrix <- matrix(0, nrow=length(subject_pcas[['rotations']]), ncol=length(subject_pcas[['rotations']]))
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- mean(sqrt(colSums((subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]])^2)))
}
}
# Cluster and plot dendrogram
hc <- hclust(dist(distance_matrix))
dendrogram <- as.dendrogram(hc)
ggraph(dendrogram, layout = "dendrogram") +
geom_edge_elbow() +  # Customize edge appearance
geom_node_text(aes(label = label), hjust = 0, size = 6) +  # Add labels
theme_bw() +  # Customize the theme
theme(text = element_text(size = 12),
axis.text = element_blank(),
panel.grid = element_blank())
ggsave('figures/pca_subjects_dendro.png', height=1000, width=1000, unit='px', dpi=150)
## VISUALIZE WITH HEAT MAP ##
plot_rotation_subject(subject_pcas[['rotations']], c(1, 2))
rm(list=ls())
library(tidyverse)
library(ggraph)
source('scripts/helpers/normalize.r')
source('scripts/helpers/plotters.r')
d <- read.csv('data/behavioral_data/MW_EEG_behavioral.csv')
# Content or movement items
content <- TRUE
if (content) {
items <- c('att', 'past', 'fut', 'self', 'ppl', 'arou', 'aff', 'image', 'ling')
} else {
items <- c('eng', 'mvmt', 'delib')
}
# Keep only subjects with 50 observations
subject_mask <- d %>%
group_by(subject) %>%
summarize(count = n()) %>%
filter(count >= 50) %>%
pull(subject)
d <- d[d$subject %in% subject_mask, ]
# Drop low confidence (< 75) responses
d <- d[d$conf > 75, c('subject', items)]
# Normalize
d <- normalize_subject_item(d)
# Run PCAs
subject_pcas <- list()
for (subject in d$subject) {
pca_data <- d[d$subject==subject, colnames(d) != 'subject']
subject_pcas[['rotations']][[paste0('subject', subject)]] <- prcomp(pca_data)$rotation[,1:3]
subject_pcas[['eigens']][[paste0('subject', subject)]] <- eigen(cov(pca_data))$values
}
# Compute distance and cluster
distance_matrix <- matrix(0, nrow=length(subject_pcas[['rotations']]), ncol=length(subject_pcas[['rotations']]))
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- mean(sqrt(colSums((subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]])^2)))
}
}
# Cluster and plot dendrogram
hc <- hclust(dist(distance_matrix))
dendrogram <- as.dendrogram(hc)
ggraph(dendrogram, layout = "dendrogram") +
geom_edge_elbow() +  # Customize edge appearance
geom_node_text(aes(label = label), hjust = 0, size = 6) +  # Add labels
theme_bw() +  # Customize the theme
theme(text = element_text(size = 12),
axis.text = element_blank(),
panel.grid = element_blank())
ggsave('figures/pca_subjects_dendro.png', height=1000, width=1000, unit='px', dpi=150)
## VISUALIZE WITH HEAT MAP ##
plot_rotation_subject(subject_pcas[['rotations']], c(1, 2))
## VISUALIZE WITH WORD CLOUD ##
plot_word_cloud(subject_pcas, c(8,15))
for (subject in d$subject) {
pca_data <- d[d$subject==subject, colnames(d) != 'subject']
subject_pcas[['rotations']][[paste0('subject', subject)]] <- prcomp(pca_data)$rotation[,1:6]
subject_pcas[['eigens']][[paste0('subject', subject)]] <- eigen(cov(pca_data))$values
}
# Compute distance and cluster
distance_matrix <- matrix(0, nrow=length(subject_pcas[['rotations']]), ncol=length(subject_pcas[['rotations']]))
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- mean(sqrt(colSums((subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]])^2)))
}
}
# Cluster and plot dendrogram
hc <- hclust(dist(distance_matrix))
dendrogram <- as.dendrogram(hc)
ggraph(dendrogram, layout = "dendrogram") +
geom_edge_elbow() +  # Customize edge appearance
geom_node_text(aes(label = label), hjust = 0, size = 6) +  # Add labels
theme_bw() +  # Customize the theme
theme(text = element_text(size = 12),
axis.text = element_blank(),
panel.grid = element_blank())
## VISUALIZE WITH WORD CLOUD ##
plot_word_cloud(subject_pcas, c(1, 7, 12, 14))
## VISUALIZE WITH WORD CLOUD ##
plot_word_cloud(subject_pcas, c(1, 7, 12, 14))
warnings()
d <- rotations_to_df(subject_pcas, subject_idxs)
subject_idxs <- c(2,5,4,7)
d <- rotations_to_df(subject_pcas, subject_idxs)
head(d)
data.frame(run=3, d)
d <- data.frame()
for (subject_idx in subject_idxs) {
rot <- data.frame(subject_pcas[['rotations']][[subject_idx]])
eigens <- subject_pcas[['eigens']][[subject_idx]]
rot <- data.frame(subject_idx, item_names_dict[rownames(rot)], rot)
d <- rbind(d, rot)
}
head(d)
d <- data.frame()
for (subject_idx in subject_idxs) {
rot <- data.frame(subject_pcas[['rotations']][[subject_idx]])
eigens <- subject_pcas[['eigens']][[subject_idx]]
rot <- data.frame(subject_idx, item = item_names_dict[rownames(rot)], rot)
d <- rbind(d, rot)
}
head(d)
d <- data.frame()
for (subject_idx in subject_idxs) {
rot <- data.frame(subject_pcas[['rotations']][[subject_idx]])
eigens <- subject_pcas[['eigens']][[subject_idx]]
rot <- data.frame(subject = subject_idx, item = item_names_dict[rownames(rot)], rot)
d <- rbind(d, rot)
}
head(d)
source("~/Dropbox/post_doc/professional/projects/MW_EEG/scripts/helpers/plotters.r")
## VISUALIZE WITH WORD CLOUD ##
plot_word_cloud(subject_pcas, c(1, 7, 12, 14))
warnings()
subject_pcas[['rotations']][[1]]
d <-  rotations_to_df(subject_pcas, subject_idxs)
head(d)
d %>%
#select(item, PC1:PC3) %>%
gather(factor, loading, PC1:(ncol(d))) %>%
head()
d %>%
#select(item, PC1:PC3) %>%
gather(factor, loading, PC1:(ncol(d))) %>%
tail()
d %>%
#select(item, PC1:PC3) %>%
gather(factor, loading, PC1:(ncol(d))) %>%
#mutate(subject = subject) %>%
ggplot(aes(x = factor, y = item, fill = loading)) +
geom_tile() +
geom_text(aes(label=round(loading, 3)), size = 5) +
scale_fill_gradient2(low = blue, high = orange) +
labs(
x = 'Factor',
y = 'Experience Sampling Item',
fill = 'Loading\nScore'
) +
facet_grid(subject~.) +
theme_bw() +
theme(axis.ticks = element_blank(),
panel.grid=element_blank(),
text=element_text(size=20),
legend.position='none',
strip.background = element_rect(fill=NA))
# Plot
orange <- brewer_pal(type='div')(9)[2]
blue <- brewer_pal(type='div')(9)[8]
d %>%
#select(item, PC1:PC3) %>%
gather(factor, loading, PC1:(ncol(d))) %>%
#mutate(subject = subject) %>%
ggplot(aes(x = factor, y = item, fill = loading)) +
geom_tile() +
geom_text(aes(label=round(loading, 3)), size = 5) +
scale_fill_gradient2(low = blue, high = orange) +
labs(
x = 'Factor',
y = 'Experience Sampling Item',
fill = 'Loading\nScore'
) +
facet_grid(subject~.) +
theme_bw() +
theme(axis.ticks = element_blank(),
panel.grid=element_blank(),
text=element_text(size=20),
legend.position='none',
strip.background = element_rect(fill=NA))
plot_word_cloud <- function(subject_pcas, subject_idxs) {
d <- rotations_to_df(subject_pcas, subject_idxs)
eigen_df <- eigens_to_df(subject_pcas, subject_idxs)
d %>%
gather(PC, loading, PC1:(ncol(d))) %>%
inner_join(eigen_df) %>%
ggplot(aes(label=item, size = abs(loading), color = loading)) +
geom_text_wordcloud(area_corr = TRUE) +
scale_size_area(max_size = 30) +
scale_color_gradientn(colors = rev(brewer_pal(type='div')(9))) +
facet_grid(subject~PC) +
theme_bw() +
theme(strip.background = element_rect(fill=NA))
}
## VISUALIZE WITH WORD CLOUD ##
plot_word_cloud(subject_pcas, c(1, 7, 12, 14))
warnings()
ggraph(dendrogram, layout = "dendrogram") +
geom_edge_elbow() +  # Customize edge appearance
geom_node_text(aes(label = label), hjust = 0, size = 6) +  # Add labels
theme_bw() +  # Customize the theme
theme(text = element_text(size = 12),
axis.text = element_blank(),
panel.grid = element_blank())
2 == 1 + 1 == 3- 1
plot.new()
2==1+1
e1 <- rbinom(5, 10, .5)
e1
e2 <- rbinom(5, 10, .5)
rel_var <- (e1 + e2) / sum(e1, e2)
rel_var
sum(rel_var)
source('computers.r')
rm(list=ls())
library(tidyverse)
library(ggraph)
source('scripts/helpers/normalize.r')
source('scripts/helpers/plotters.r')
source('computers.r')
rm(list=ls())
library(tidyverse)
library(ggraph)
source('scripts/helpers/normalize.r')
source('scripts/helpers/plotters.r')
source('scripts/helpers/computers.r')
d <- read.csv('data/behavioral_data/MW_EEG_behavioral.csv')
# Content or movement items
content <- TRUE
if (content) {
items <- c('att', 'past', 'fut', 'self', 'ppl', 'arou', 'aff', 'image', 'ling')
} else {
items <- c('eng', 'mvmt', 'delib')
}
# Keep only subjects with 50 observations
subject_mask <- d %>%
group_by(subject) %>%
summarize(count = n()) %>%
filter(count >= 50) %>%
pull(subject)
d <- d[d$subject %in% subject_mask, ]
# Drop low confidence (< 75) responses
d <- d[d$conf > 75, c('subject', items)]
# Normalize
d <- normalize_subject_item(d)
# Run PCAs
subject_pcas <- list()
for (subject in d$subject) {
pca_data <- d[d$subject==subject, colnames(d) != 'subject']
subject_pcas[['rotations']][[paste0('subject', subject)]] <- prcomp(pca_data)$rotation[,1:6]
subject_pcas[['eigens']][[paste0('subject', subject)]] <- eigen(cov(pca_data))$values
}
# Compute distance and cluster
distance_matrix <- matrix(0, nrow=length(subject_pcas[['rotations']]), ncol=length(subject_pcas[['rotations']]))
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- weighted_distance(subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]])
}
}
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- weighted_distance(subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]],
e1=subject_pcas[['eigens']][i], e2=subject_pcas[['eigens']][j])
}
}
e1
subject_pcas[['eigens']][[i]]
subject_pcas[['eigens']][[i]] + subject_pcas[['eigens']][[j]]
sum(subject_pcas[['eigens']][[i]], subject_pcas[['eigens']][[j]])
i
j
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- weighted_distance(subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]],
e1=subject_pcas[['eigens']][i], e2=subject_pcas[['eigens']][j])
}
}
source("~/Dropbox/post_doc/professional/projects/MW_EEG/scripts/helpers/computers.r")
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- weighted_distance(subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]],
e1=subject_pcas[['eigens']][i], e2=subject_pcas[['eigens']][j])
}
}
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- weighted_distance(subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]],
e1=subject_pcas[['eigens']][[i]], e2=subject_pcas[['eigens']][[j]])
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- weighted_distance(subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]],
e1=subject_pcas[['eigens']][[i]], e2=subject_pcas[['eigens']][[j]])
}
}
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- weighted_distance(subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]],
e1=subject_pcas[['eigens']][[i]], e2=subject_pcas[['eigens']][[j]])
}
}
source("~/Dropbox/post_doc/professional/projects/MW_EEG/scripts/helpers/computers.r")
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- weighted_distance(subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]],
e1=subject_pcas[['eigens']][[i]], e2=subject_pcas[['eigens']][[j]])
}
}
warnings()
subject_pcas <- list()
Nfactors <- 6
for (subject in d$subject) {
pca_data <- d[d$subject==subject, colnames(d) != 'subject']
subject_pcas[['rotations']][[paste0('subject', subject)]] <- prcomp(pca_data)$rotation[,1:Nfactors]
subject_pcas[['eigens']][[paste0('subject', subject)]] <- eigen(cov(pca_data))$values[1:Nfactors]
}
# Compute distance and cluster
distance_matrix <- matrix(0, nrow=length(subject_pcas[['rotations']]), ncol=length(subject_pcas[['rotations']]))
for (i in 1:length(subject_pcas[['rotations']])) {
for (j in 1:length(subject_pcas[['rotations']])) {
# Frobenius norm of difference between two matrices
# distance_matrix[i,j] <- norm(subject_pcas[[i]] - subject_pcas[[j]], type='F')
# Mean Euclidean distance between each column of two matrices
# Could expand this to weight the average by the eigenvalues
distance_matrix[i,j] <- weighted_distance(subject_pcas[['rotations']][[i]] - subject_pcas[['rotations']][[j]],
e1=subject_pcas[['eigens']][[i]], e2=subject_pcas[['eigens']][[j]])
}
}
distance_matrix
hc <- hclust(dist(distance_matrix))
dendrogram <- as.dendrogram(hc)
ggraph(dendrogram, layout = "dendrogram") +
geom_edge_elbow() +  # Customize edge appearance
geom_node_text(aes(label = label), hjust = 0, size = 6) +  # Add labels
theme_bw() +  # Customize the theme
theme(text = element_text(size = 12),
axis.text = element_blank(),
panel.grid = element_blank())
## VISUALIZE WITH WORD CLOUD ##
plot_word_cloud(subject_pcas, c(5,6,1,7))
distance_matrix
subject_pcas[['rotations']][[1]]
source("~/Dropbox/post_doc/professional/projects/MW_EEG/scripts/helpers/plotters.r")
## VISUALIZE WITH WORD CLOUD ##
plot_word_cloud(subject_pcas, c(5,6,1,7))
ggraph(dendrogram, layout = "dendrogram") +
geom_edge_elbow() +  # Customize edge appearance
geom_node_text(aes(label = label), hjust = 0, size = 6) +  # Add labels
theme_bw() +  # Customize the theme
theme(text = element_text(size = 12),
axis.text = element_blank(),
panel.grid = element_blank())
source("~/Dropbox/post_doc/professional/projects/MW_EEG/scripts/helpers/plotters.r")
## VISUALIZE WITH WORD CLOUD ##
plot_word_cloud(subject_pcas, c(5,6,1,7))
warnings()
source("~/Dropbox/post_doc/professional/projects/MW_EEG/scripts/helpers/plotters.r")
plot.new()
warnings()
## VISUALIZE WITH WORD CLOUD ##
plot_word_cloud(subject_pcas, c(5,6,1,7))
source("~/Dropbox/post_doc/professional/projects/MW_EEG/scripts/helpers/plotters.r")
plot.new()
q()
